---
title: "analyse_shs_groupe_D_moins_30ans"
author: "Groupe D"
date: '2022-05-04'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Chargement des librairies

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(effsize)
library(Rmisc)
library(Hmisc)
library(ggplot2)
library(gmodels)
library(survey)
library(effects)
library(rockchalk)
library(nortest)
library(pastecs)
library(sjPlot)
library(psych)
library(kableExtra)
library(car)
library(PMCMRplus)
library(lm.beta)
library(pwr)
library(plotrix)
```

# Chargement et nettoyage des données

```{r, message=FALSE, warning=FALSE}
data <- read_csv("../data/value_data.csv") 
data$`Duration (in seconds)`<- as.numeric(data$`Duration (in seconds)`)
data$amabilite_1 <- as.numeric(data$amabilite_1)
data$amabilite_2 <- as.numeric(data$amabilite_2)
data$age_1 <- as.numeric(data$age_1)

data <- subset(data,`Duration (in seconds)` > 600 & `Duration (in seconds)` < 1800 )

data <- subset(data, Finished == 1 & Progress == 100)

data <- subset(data, amabilite_1 > 0 & amabilite_2 > 0 & genre < 3)

data <- subset(data, amabilite_1 < 6 & amabilite_2 < 6)

data <- subset(data, age_1 < 30)

data <- data %>% 
  mutate(article = if_else(`manifeste_time_c_First Click` > 0, "Croissance verte", "0"))

data$article[data$`manifeste_time_d_First Click` > 0] <- "Decroissance" 

data <- data[c("genre" , "article" , "amabilite_1" , "amabilite_2", "age_1", "regime" , "diplome" , "emploi" , "enfant")]

data$amabilite_1 = 5 - data$amabilite_1 + 1

data$genre[data$genre == 2] <- "Masculin"

data$genre[data$genre == 1] <- "Feminin"

data$difference <- abs(data$amabilite_1 - data$amabilite_2)

```

# Description des données

```{r}
head(data)
describe(data)
```

### Taille population :
```{r}
length(data$article)
```

## Répartition du genre :
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = article, fill = genre)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```

## Répartition de l'âge :
```{r}
age.boxplot <- ggplot(data, aes(x = article, y = age_1, fill=genre)) # créer l'objet ainsi que insérer les data
age.boxplot + # + ajoute les layers
  geom_boxplot(size = 0.7,  alpha = 1) + # quelques options du geom
  labs(x = "Article", y = "Age")+ # les légendes 
  theme_bw() # un theme pour faire joli
```

### Valeurs descriptives Amabilite_1 :
```{r}
test.desc <- aggregate(formula = amabilite_1 ~ genre*article, data = data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```

```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_1, fill = genre)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_1, fill = article)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_1)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge", fill = "Orange") + 
  ylab("Proportion") +
  theme_bw()
```

```{r}
df <- ddply(data, c("genre", "article"), dplyr::summarize,
            Mean = mean(amabilite_1, na.rm=T),
            SE   = std.error(amabilite_1, na.rm=T))
df

genre.bar <- ggplot(df , aes(x = article, y = Mean, fill = genre)) 
genre.bar +
  geom_bar(stat = "identity", position = "dodge") + 
  ylab("Moyenne amabilite_1") +
  geom_errorbar(aes(ymin = Mean-SE, ymax = Mean+SE), width = 0.2, position = position_dodge(0.9)) +
  theme_bw()
```


### Valeurs descriptives Amabilite_2 :
```{r}
test.desc <- aggregate(formula = amabilite_2 ~ genre*article, data = data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```

```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_2, fill = genre)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_2, fill = article)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = amabilite_2)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge", fill = "Orange") + 
  ylab("Proportion") +
  theme_bw()
```

```{r}
df <- ddply(data, c("genre", "article"), dplyr::summarize,
            Mean = mean(amabilite_2, na.rm=T),
            SE   = std.error(amabilite_2, na.rm=T))
df

genre.bar <- ggplot(df , aes(x = article, y = Mean, fill = genre)) 
genre.bar +
  geom_bar(stat = "identity", position = "dodge") + 
  ylab("Moyenne amabilite_2") +
  geom_errorbar(aes(ymin = Mean-SE, ymax = Mean+SE), width = 0.2, position = position_dodge(0.9)) +
  theme_bw()
```

## Disparité des réponses pour les deux items :
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = difference, fill = genre)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge") + 
  ylab("Proportion") +
  theme_bw()
```
```{r}
genre.bar <- ggplot(data, aes(y = (..count..)/sum(..count..), x = difference)) 
genre.bar +
  scale_y_continuous(labels = scales::percent) +
  geom_bar(position = "dodge", fill = "Orange") + 
  ylab("Proportion") +
  theme_bw()
```


# Assomptions

## Normalité

Interprétation : 

La normalité peut-être controlée de manière visuelle :

- histogramme (devraient suivre une courbe normale)

- boxplots (moyenne et médiane au milieu de la boite, moustache égales, pas d’outliers)

- qqplot (devraient suivre la diagonale)


Avec des chiffres :

- test de Liliefors si p-value < 0.05 alors l'hypothèse selon laquelle la distribution suit une loi normale est rejetée (résultat significatif), souvent sgnificatif si N > 50.

- Skew and Kurtosis : Pour avoir une distribution la plus proche d'une loi normale on veut skew très proche de 0 pour assurer la symétrie de la distribution et Kurtosis très proche de 0 pour assurer que la distribution des valeurs extrêmes soit proche de celle d'une loi normale.  

### Amabilité 1
```{r}
norm.amabilite_1 <- ggplot(data, aes(amabilite_1))  + 
  geom_histogram(aes(y = ..density..), fill = "white", colour = "black", binwidth = 1) + 
  labs(
    x= "Amabilite_1",
    y = "Proportion") + 
  stat_function(fun=dnorm, args=list(mean = mean(data$amabilite_1, na.rm = TRUE), sd = sd(data$amabilite_1, na.rm = TRUE)), colour = "blue", size=1) +
  theme_bw()

norm.amabilite_1
```
```{r}
qplot(sample = data$amabilite_1, stat="qq")
```
```{r}
lillie.test(data$amabilite_1)
```
```{r}
length(data$amabilite_1)
```
```{r}
describe(data$amabilite_1)
```

```{r}
test.desc <- aggregate(formula = amabilite_1 ~ genre*article, data = data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```



### Amabilité 2
```{r}
norm.amabilite_2 <- ggplot(data, aes(amabilite_2))  + 
  geom_histogram(aes(y = ..density..), fill = "white", colour = "black", binwidth = 1) + 
  labs(
    x= "Amabilite_2",
    y = "Proportion") + 
  stat_function(fun=dnorm, args=list(mean = mean(data$amabilite_2, na.rm = TRUE), sd = sd(data$amabilite_2, na.rm = TRUE)), colour = "blue", size=1) +
  theme_bw()

norm.amabilite_2
```
```{r}
qplot(sample = data$amabilite_2, stat="qq")
```
```{r}
lillie.test(data$amabilite_2)
```
```{r}
length(data$amabilite_2)
```
```{r}
describe(data$amabilite_2)
```

```{r}
test.desc <- aggregate(formula = amabilite_2 ~ genre*article, data = data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```

## Valeurs extrêmes

### Amabilité 1
```{r}
out <- boxplot(data$amabilite_1)$out #Valeurs des VE
out
```

### Amabilité 2
```{r}
out <- boxplot(data$amabilite_2)$out #Valeurs des VE
```


```{r}
out_ind <- which(data$amabilite_2 %in% c(out))
out_ind
data[out_ind, ]
```

Après étude du profils des outliers ils ne semblent pas abérrants et au contraire semblent représenter un groupe homogène de personne, on a donc décider de les conserver sous l'hypothèse qu'ils ne sont probablement outlier qu'à cause de la petite taille de la population.
```{r}
# data <- data[-out_ind,]
```


## Homogénéité des variances :

Interprétation : Il faut que les variances de chaque variable soient égales afin de pouvoir être comparable.

- on utilise soit le test de Lavene (qui doit être non significatif) càd avoir une p-value > 0.05 pour qu'on considère que les variances soient homogènes (ici p-value correspond a la colonne Pr(<F))

- on utilise hartley Test (qui doit être non significatif) càd avoir une p-value > 0.05 pour qu'on considère que les variances soient homogènes.

### Amabilité 1
```{r}
# Levene test
leveneTest(amabilite_1 ~ genre*article, data=data, center = mean)  %>%  
  knitr::kable(., digits = 2, format = "html", align = 'c') %>% 
  kableExtra::kable_styling(., bootstrap_options = "striped")
```
```{r}
test.desc <- aggregate(formula = amabilite_1 ~ genre*article, data =data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```

```{r}
hartleyTest(formula = amabilite_1 ~ interaction(genre, article), data=data)
```


### Amabilité 2
```{r}
# Levene test
leveneTest(amabilite_2 ~ genre*article, data=data, center = mean)  %>%  
  knitr::kable(., digits = 2, format = "html", align = 'c') %>% 
  kableExtra::kable_styling(., bootstrap_options = "striped")
```
```{r}
test.desc <- aggregate(formula = amabilite_2 ~ genre*article, data = data, FUN = describe) %>% as.data.frame()
tab_df(test.desc)
```

```{r}
hartleyTest(formula = amabilite_2 ~ interaction(genre, article), data=data)
```


## Heteroscedasticité

Interprétation : Il convient de contrôler que la variance des résiduels soient égales à chaque degré de nos prédicteurs; qu’ils soient donc homoscedastique. Sans quoi nos conditions/variables prédictrice continues ne serait pas comparables.

Ceci se teste par inspection visuelle: On doit obtenir une ligne horizontale dans le plot des studentized residuals pour que nos variables soient homoscedastiques. On doit aussi obtenir une diagonale dans le qqplot des residuels.

### Amabilité 1
```{r}
mod1 <- lm(amabilite_1 ~ genre + article + genre*article, data = data, na.action = na.omit)

#fitted values pour plot et std. and studentised residuals dans nos données
data$fitted <- mod1$fitted.values
data$standardized.residuals<- rstandard(mod1)
data$studentized.residuals<-rstudent(mod1)

# plot des fitted values against std. residuals
scatter.resid <- ggplot(data, aes(fitted, studentized.residuals))
scatter.resid + geom_point() + geom_smooth(method = "lm", colour = "Blue")+ labs(x = "Fitted
Values", y = "Studentized Residual")

# qqplot des residuels
qqplot.resid <- qplot(sample = data$studentized.residuals, stat="qq") + labs(x =
"Theoretical Values", y = "Observed Values")
qqplot.resid
```

### Amabilité 2
```{r}
mod2 <- lm(amabilite_2 ~ genre + article + genre*article, data = data, na.action = na.omit)

#fitted values pour plot et std. and studentised residuals dans nos données
data$fitted <- mod2$fitted.values
data$standardized.residuals<- rstandard(mod2)
data$studentized.residuals<-rstudent(mod2)

# plot des fitted values against std. residuals
scatter.resid <- ggplot(data, aes(fitted, studentized.residuals))
scatter.resid + geom_point() + geom_smooth(method = "lm", colour = "Blue")+ labs(x = "Fitted
Values", y = "Studentized Residual")

# qqplot des residuels
qqplot.resid <- qplot(sample = data$studentized.residuals, stat="qq") + labs(x =
"Theoretical Values", y = "Observed Values")
qqplot.resid
```

## Independance

On peut contrôler ceci avec un test de Durbin-Watson

Interprétation : On veut que les observations soient indépendantes pour pouvoir réaliser la régression linéaire et pour cela on doit avoir une p-value > 0.05 pour que l'hypothèse nulle de non auto-corrélation soit validée par le test. 

### Amabilité 1
```{r}
dwt(mod1)
```

### Amabilité 2
```{r}
dwt(mod2)
```

## Mutlicolinearité

Prédicteurs (Variables indépendantes) ne doivent pas être parfaitement corrélés.

Interprétation : To check for multicollinearity, use the VIF values. If these values are less than 10 then that indicates there probably isn’t cause for concern. If you take the average of VIF values, and this average is not substantially greater than 1, then that also indicates that there’s no cause for concern.

### Amabilité 1
```{r}
vif(mod1)
1/vif(mod1)
mean(vif(mod1))
```

### Amabilité 2
```{r}
vif(mod2)
1/vif(mod2)
mean(vif(mod2))
```

## Linéarité :

La relation entre les variables doit suivre une relation linéaire.

inspection visuelle : Ce premier graphique permet de savoir si les valeurs prédites (ou fitted values, en x) et les résidus (ou residuals, en y) suivent une distribution bivariée linéaire. Pour que la condition de linéarité du modèle soit respectée, le segment représenté en rouge doit se situer, idéalement, sur une valeur résiduelle (ou y) égale à 0. 
Cf les plots "plot(model.XX, which = 1)" de la dernière partie sur la régression linéaire pour valider cela

## Sphéricité :

Pour les mesures répétées à plus de 3 conditions. Or dans notre étude les variables dépendantes amabilite ne sont mesurées qu'une fois par participants donc pas de test de sphéricité nécessaire ici.


# Régression Linéaire

Pour chaque model on peut regarder sa p-value pour déterminer si les résultats sont significatis ou non (cad si on observe un effet significatif), donc si p-value < 0.05 alors les effets observés sont significatifs et on peut les exploiter.

Ici model.0X est un modèle simple et model.1X est un modèle avec une VI en plus mais grâce à la mesure d'anova on peut savoir si model.1X apporte plus d'info ou non. Si anova(model.0X, model.1X) donne une p-value(Pr(>F)) > 0.05 alors model.1X est inutile comparé à model.0X.

### Amabilité 1
```{r}
model.01 <- lm(amabilite_1 ~ article + genre, data = data, na.action = na.omit)
summary(model.01)
plot(model.01, which = 1)

#standardized coeff in case needed
lm.beta(model.01)

plot(allEffects(model.01))

```


```{r}
data %>% 
  ggplot() +
  aes(x = article, color = genre, group = genre, y = amabilite_1) +
  stat_summary(fun.y = mean, geom = "line") + 
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", fun.args = list(mult = 1))
```

```{r}
plot <- ggplot(data, aes(article, amabilite_1, colour = genre)) +
  geom_point(position = position_jitter(width = 0.3, height = 0.1)) + 
  geom_smooth(aes(group = genre),method = lm) +
  labs(
    title = "Scatterplots for test scores",
    subtitle = "s",
    caption = "c",
    x = "x",
    y = "y") +
  theme_bw()

plot
```


```{r}
model.11 <- lm(amabilite_1 ~ genre + article + genre*article, data = data, na.action = na.omit)
summary(model.11)
plot(model.11, which = 1)
```

```{r}
anova(model.01, model.11)
```


### Amabilité 2
```{r}
model.02 <- lm(amabilite_2 ~ article + genre, data = data, na.action = na.omit)
summary(model.02)

#standardized coeff in case needed
lm.beta(model.02)

plot(model.02, which = 1)

plot(allEffects(model.02))
```

```{r}
data %>% 
  ggplot() +
  aes(x = article, color = genre, group = genre, y = amabilite_2) +
  stat_summary(fun.y = mean, geom = "line") + 
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", fun.args = list(mult = 1))
```

```{r}
plot <- ggplot(data, aes(article, amabilite_2, colour = genre)) +
  geom_point(position = position_jitter(width = 0.3, height = 0.1)) + 
  geom_smooth(aes(group = genre),method = lm) +
  labs(
    title = "Scatterplots for test scores",
    subtitle = "s",
    caption = "c",
    x = "x",
    y = "y") +
  theme_bw()

plot
```

```{r}
model.12 <- lm(amabilite_2 ~ genre + article + genre*article, data = data, na.action = na.omit)
summary(model.12)
plot(model.12, which = 1)
```

```{r}
anova(model.02, model.12)
```


# Fidélité : Corrélation entre les deux items :

Pas de test de alpha nécessaire ici car nous avons que deux items pour mesurer l'amabilité, un simple test de corrélation est suffisant. (le test alpha a quand même été réalisé pour information et idéalement sa valeur doit être autour de 0.7 et supérieur à 0.3 sinon cela signifie que nos deux items ne sont pas cohérent entre eux)

La corrélation entre les deux items doit être supérieur à 0.3 pour être significative. Sinon cela signifie que les deux items ne mesurent pas la même chose. 

```{r}
cor_res <- cor(data$amabilite_1, data$amabilite_2,  method = "pearson", use = "complete.obs")
cor_res
```

```{r}
amabilite <- data[, c("amabilite_1", "amabilite_2")]
psych::alpha(amabilite)
```

# Analyse de puissance a posteriori :

Power a posteriori is the probability of making a correct decision (to reject the null hypothesis) when the null hypothesis is false. It is represented by the probability (1 - Beta) with beta the probalility of making a Type II error i.e the false acceptance of the null hypothesis.

Here the null hypothesis is that there are no effects between our groups, and our expectation is to reject it i.e show that there are significant effects.

We want a power of at least 0.80 in general, so that the type II error beta is less than 0.20.

To obtain the power a posteriori we need to have the following value :

- significance level alpha : probability of making a type I error i.e the false rejection of the null hypothesis (generally taken as 0.05)

- The effect size : f2 = R² / (1 - R²) with R² that is multiple R-squared from model.0X the Cohen suggests f2 values of 0.02, 0.15, and 0.35 represent small, medium, and large effect sizes. 

- numerator of degrees of freedom : u = the number of predictors - 1 (here we have 2 predictors : genre and article)

- denominator of degrees of freedom : v =  Population size - number of predictors


## Amabilité 1

### power 
```{r}
R2 <- summary(model.01)$r.squared
f2 <- R2 / (1 - R2)

pwr.f2.test(u = 2 - 1, v = length(data$amabilite_1) - 2, f2 = f2, sig.level = 0.05 , power = NULL )

```


### population size N to have a power of 0.80
```{r}
res <- pwr.f2.test(u = 2 - 1, v = NULL, f2 = f2, sig.level = 0.05 , power = 0.80)
N <- res$v + 2
N
```
### actual population size
```{r}
length(data$amabilite_1)
```



## Amabilité 2

### power 
```{r}
R2 <- summary(model.02)$r.squared
f2 <- R2 / (1 - R2)

pwr.f2.test(u = 2 - 1, v = length(data$amabilite_1) - 2, f2 = f2, sig.level = 0.05 , power = NULL )

```


### population size N to have a power of 0.80
```{r}
res <- pwr.f2.test(u = 2 - 1, v = NULL, f2 = f2, sig.level = 0.05 , power = 0.80)
N <- res$v + 2
N
```
### actual population size
```{r}
length(data$amabilite_1)
```


